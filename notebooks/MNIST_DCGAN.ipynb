{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4TF MNIST GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcLhx7R4YuUv",
        "colab_type": "text"
      },
      "source": [
        "# MNIST GAN in Swift for TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvZux3i-YzNv",
        "colab_type": "text"
      },
      "source": [
        "## Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS6maJ7vXHSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%install-location $cwd/swift-install\n",
        "%install '.package(url: \"https://github.com/tensorflow/swift-models\", .branch(\"tensorflow-0.6\"))' Datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvaI1fPZRfQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import Foundation\n",
        "import Datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eXM0Elku26P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%include \"EnableIPythonDisplay.swift\"\n",
        "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44nZFdVw2yyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Python\n",
        "let plt = Python.import(\"matplotlib.pyplot\")\n",
        "let np = Python.import(\"numpy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFp59EhiY3Y4",
        "colab_type": "text"
      },
      "source": [
        "## Loading MNIST\n",
        "\n",
        "[tensorflow/swift-models](https://github.com/tensorflow/swift-models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcNH7ENBZhhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let batchSize = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDEoKPPYZRGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let mnist = MNIST(batchSize: batchSize, flattening: false, normalizing: true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ppaI_0SZKh2",
        "colab_type": "text"
      },
      "source": [
        "## Building a DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzGTKJc0u8fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let zDim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHjdUaVosD_2",
        "colab_type": "text"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywzfKlWZsGm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct Generator: Layer {\n",
        "    var flatten = Flatten<Float>()\n",
        "\n",
        "    var dense1 = Dense<Float>(inputSize: zDim, outputSize: 7 * 7 * 256) \n",
        "    var batchNorm1 = BatchNorm<Float>(featureCount: 7 * 7 * 256)\n",
        "    // leaky relu\n",
        "    // reshape\n",
        "\n",
        "    var transConv2D1 = TransposedConv2D<Float>(\n",
        "        filterShape: (5, 5, 128, 256),\n",
        "        strides: (1, 1),\n",
        "        padding: .same\n",
        "    )\n",
        "    // flatten\n",
        "    var batchNorm2 = BatchNorm<Float>(featureCount: 7 * 7 * 128)\n",
        "    // leaky relu\n",
        "\n",
        "    var transConv2D2 = TransposedConv2D<Float>(\n",
        "        filterShape: (5, 5, 64, 128),\n",
        "        strides: (2, 2),\n",
        "        padding: .same\n",
        "    )\n",
        "    // flatten\n",
        "    var batchNorm3 = BatchNorm<Float>(featureCount: 14 * 14 * 64)\n",
        "    // leaky relu\n",
        "\n",
        "    var transConv2D3 = TransposedConv2D<Float>(\n",
        "        filterShape: (5, 5, 1, 64),\n",
        "        strides: (2, 2),\n",
        "        padding: .same\n",
        "    )\n",
        "    // tanh\n",
        "\n",
        "\n",
        "    @differentiable \n",
        "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> { \n",
        "        let x1 = leakyRelu(input.sequenced(through: dense1, batchNorm1))\n",
        "        let x1Reshape = x1.reshaped(to: TensorShape(x1.shape.contiguousSize / (7 * 7 * 256), 7, 7, 256))\n",
        "        let x2 = leakyRelu(x1Reshape.sequenced(through: transConv2D1, flatten, batchNorm2))\n",
        "        let x2Reshape = x2.reshaped(to: TensorShape(x2.shape.contiguousSize / (7 * 7 * 128), 7, 7, 128))\n",
        "        let x3 = leakyRelu(x2Reshape.sequenced(through: transConv2D2, flatten, batchNorm3))\n",
        "        let x3Reshape = x3.reshaped(to: TensorShape(x3.shape.contiguousSize / (14 * 14 * 64), 14, 14, 64))\n",
        "        return tanh(transConv2D3(x3Reshape))\n",
        "    } \n",
        "} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo6NLpr6vfds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var generator = Generator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stEdaj4QcM5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let noise = Tensor<Float>(randomNormal: TensorShape(1, zDim))\n",
        "let generatedImage = generator(noise)\n",
        "generatedImage.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PspNJrlnsMwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(generatedImage.reshaped(to: TensorShape(28, 28)).makeNumpyArray())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeMeZ-RxvHf",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RyxKhl8DotBI",
        "colab": {}
      },
      "source": [
        "struct Discriminator: Layer {\n",
        "      var conv2D1 = Conv2D<Float>(\n",
        "          filterShape: (5, 5, 1, 64),\n",
        "          strides: (2, 2),\n",
        "          padding: .same\n",
        "      )\n",
        "      // leaky relu\n",
        "      var dropout = Dropout<Float>(probability: 0.3)\n",
        "\n",
        "      var conv2D2 = Conv2D<Float>(\n",
        "          filterShape: (5, 5, 64, 128),\n",
        "          strides: (2, 2),\n",
        "          padding: .same\n",
        "      )\n",
        "      // leaky relu\n",
        "      // dropout\n",
        "\n",
        "      var flatten = Flatten<Float>()\n",
        "      var dense = Dense<Float>(inputSize: 6272, outputSize: 1)\n",
        "\n",
        "      @differentiable \n",
        "      public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> { \n",
        "          let x1 = dropout(leakyRelu(conv2D1(input)))\n",
        "          let x2 = dropout(leakyRelu(conv2D2(x1)))\n",
        "          return x2.sequenced(through: flatten, dense)\n",
        "      } \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XCYHPH_qPaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var discriminator = Discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz75syIpRv99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator(generatedImage)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAXVzcGFZTAn",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrlIsz38d0Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@differentiable\n",
        "func generatorLoss(fakeLabels: Tensor<Float>) -> Tensor<Float> {\n",
        "    sigmoidCrossEntropy(logits: fakeLabels,\n",
        "                        labels: Tensor(ones: fakeLabels.shape))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0CNw8avd0jR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@differentiable\n",
        "func discriminatorLoss(realLabels: Tensor<Float>, fakeLabels: Tensor<Float>) -> Tensor<Float> {\n",
        "    let realLoss = sigmoidCrossEntropy(logits: realLabels,\n",
        "                                       labels: Tensor(ones: realLabels.shape)) // should say it's real, 1\n",
        "    let fakeLoss = sigmoidCrossEntropy(logits: fakeLabels,\n",
        "                                       labels: Tensor(zeros: fakeLabels.shape)) // should say it's fake, 0\n",
        "    return realLoss + fakeLoss // accumaltive\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z14c8KOyqy4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let optG = Adam(for: generator, learningRate: 0.0001)\n",
        "let optD = Adam(for: discriminator, learningRate: 0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI6mNGO7oAJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnx_jDndZivO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in 0...epochs {\n",
        "    Context.local.learningPhase = .training\n",
        "    for i  in 0..<(mnist.trainingSize / batchSize)+1  {\n",
        "        let realImages = mnist.trainingImages.minibatch(at: i, batchSize: i * batchSize >= mnist.trainingSize ? (mnist.trainingSize - ((i - 1) * batchSize)) : batchSize)\n",
        "\n",
        "        // train generator\n",
        "        let noiseG = Tensor<Float>(randomNormal: TensorShape(batchSize, zDim))\n",
        "        let ùõÅgenerator = generator.gradient { generator -> Tensor<Float> in\n",
        "            let fakeImages = generator(noiseG)\n",
        "            let fakeLabels = discriminator(fakeImages)\n",
        "            let loss = generatorLoss(fakeLabels: fakeLabels)\n",
        "            return loss\n",
        "        }\n",
        "        optG.update(&generator, along: ùõÅgenerator)\n",
        "\n",
        "        // train discriminator\n",
        "        let noiseD = Tensor<Float>(randomNormal: TensorShape(batchSize, zDim))\n",
        "        let fakeImages = generator(noiseD)\n",
        "        \n",
        "        let ùõÅdiscriminator = discriminator.gradient { discriminator -> Tensor<Float> in\n",
        "            let realLabels = discriminator(realImages)\n",
        "            let fakeLabels = discriminator(fakeImages)\n",
        "            let loss = discriminatorLoss(realLabels: realLabels, fakeLabels: fakeLabels)\n",
        "            return loss\n",
        "        }\n",
        "        optD.update(&discriminator, along: ùõÅdiscriminator)\n",
        "    }\n",
        "\n",
        "    // test\n",
        "    Context.local.learningPhase = .inference\n",
        "\n",
        "    // render images\n",
        "    let generatedImage = generator(noise)\n",
        "    plt.imshow(generatedImage.reshaped(to: TensorShape(28, 28)).makeNumpyArray())\n",
        "    plt.show()\n",
        "    \n",
        "    // print loss\n",
        "    let generatorLoss_ = generatorLoss(fakeLabels: generatedImage)\n",
        "    print(\"epoch: \\(epoch) | Generator loss: \\(generatorLoss_)\")\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}